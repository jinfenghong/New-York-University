{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc33\\anaconda3\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas_datareader.data as web\n",
    "import math\n",
    "import xlsxwriter\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetPreprocessing:\n",
    "    PATH = \"Tweets/\"\n",
    "    def __init__(self,s):\n",
    "        self.stock = s\n",
    "        \n",
    "    def start(self):\n",
    "        self.getTweetData()\n",
    "        self.preprocessingTweet()\n",
    "        self.getYahooData()\n",
    "        self.preprocessingYahoo()\n",
    "        self.processingBoth()\n",
    "        self.df_full.to_csv('Clean_Data/${}_pred.csv'.format(self.stock))\n",
    "    \n",
    "    def getTweetData(self):\n",
    "        xls = pd.ExcelFile(self.PATH+'{}.xlsx'.format(self.stock))\n",
    "        \n",
    "        df = pd.read_excel(xls, header = 0,encoding='latin-1', sheet_name = \"Stream\")\n",
    "        Tweet = df['Tweet content']\n",
    "        df_results = pd.DataFrame(self.sentimentScore(Tweet))\n",
    "        \n",
    "        # Combining the two dataframes\n",
    "        df_tweets = pd.merge(df, df_results, left_index=True, right_index=True)\n",
    "        \n",
    "        # Choose the common range for the dataframes to be used for all tweet data\n",
    "        df_tweets = df_tweets[(df_tweets['Date'] >= '2016-03-28') & (df_tweets['Date'] <= '2016-06-15')]\n",
    "        \n",
    "        # Adding a datetime column\n",
    "        df_tweets['datetime'] = pd.to_datetime(df_tweets['Date']) # change of Date column to datetime columns        \n",
    "        # Slimming down the stream into a dataframe with only relevant columns\n",
    "        self.df_tweet = df_tweets[['Favs','RTs','Followers','Following', 'Is a RT','compound','neg','neu','pos','datetime']]\n",
    "        \n",
    "    def preprocessingTweet(self):\n",
    "        # Remove tweets were compound is zero, i.e. sentiment is neutral\n",
    "        self.df_tweet = self.df_tweet[(self.df_tweet[['compound']] != 0).all(axis=1)]\n",
    "        \n",
    "        # Create new column with the 'compound' multiplied by nr of followers of the account\n",
    "        self.df_tweet['Compound_multiplied'] = self.df_tweet['compound'] * self.df_tweet['Followers']\n",
    "        \n",
    "        # Remove rows where 'Followers' is NaN\n",
    "        self.df_tweet.dropna(subset=['Followers'],inplace=True)\n",
    "        \n",
    "        # Scale the column \"Compound_multiplied\"\n",
    "        x_1 = self.df_tweet[['Compound_multiplied']].values.astype(float)\n",
    "\n",
    "        scaler = StandardScaler().fit(x_1)\n",
    "\n",
    "        scaled_data = scaler.transform(x_1)\n",
    "\n",
    "        self.df_tweet['Compound_multiplied_scaled'] = scaled_data\n",
    "        \n",
    "        # Create a dataframe with daily MEANS of each column\n",
    "        self.df_daily_mean=(self.df_tweet.groupby(self.df_tweet.datetime).mean())\n",
    "        \n",
    "        # Remove weekends from df_daily_mean\n",
    "        self.df_daily_mean = self.df_daily_mean[self.df_daily_mean.index.dayofweek < 5]\n",
    "        \n",
    "    def getYahooData(self):\n",
    "        #import pandas_datareader.data as web\n",
    "        start = dt.datetime(2016, 3, 28)\n",
    "        end =  dt.datetime(2016, 6, 14) #dt.datetime.now()\n",
    "\n",
    "        self.df_stock = web.DataReader(self.stock, 'yahoo', start, end)\n",
    "                \n",
    "    def preprocessingYahoo(self):\n",
    "        # measure of volatility\n",
    "        self.df_stock['HiLo_vola_stock'] = (self.df_stock['High'] - self.df_stock['Low']) / self.df_stock['Adj Close'] * 100.0\n",
    "        \n",
    "        # daily percent change\n",
    "        self.df_stock['Pct_change_stock'] = (self.df_stock['Close'] - self.df_stock['Open']) / self.df_stock['Open'] * 100.0\n",
    "        \n",
    "    def processingBoth(self):\n",
    "        self.df_full = pd.concat([self.df_stock[['Volume','Adj Close','HiLo_vola_stock','Pct_change_stock']],\n",
    "                             self.df_daily_mean], axis=1, sort=False)\n",
    "        \n",
    "        # Impute missing data with their means\n",
    "        self.df_full[['Favs','RTs','Followers','Following','Is a RT','compound','neg','neu','pos','Compound_multiplied','Compound_multiplied_scaled']] \\\n",
    "        .fillna(value=self.df_full[['Favs','RTs','Followers','Following','Is a RT','compound','neg','neu','pos','Compound_multiplied','Compound_multiplied_scaled']].mean(),inplace=True)\n",
    "\n",
    "        # Remove missing Pct_change_stock data\n",
    "        self.df_full.dropna(subset=['Pct_change_stock'],inplace=True) \n",
    "        self.df_full.dropna(subset=['Compound_multiplied_scaled'],inplace=True) \n",
    "                \n",
    "        buy_or_sell = []\n",
    "        for i in self.df_full['Pct_change_stock']:\n",
    "            if i >= 0:\n",
    "                buy_or_sell.append(1)\n",
    "            elif i < 0:\n",
    "                buy_or_sell.append(-1)\n",
    "            else:\n",
    "                buy_or_sell.append(np.nan)\n",
    "\n",
    "        #Adds -1 or +1 to the column based on if 'Predicted_change' is negative or positive\n",
    "        self.df_full['Buy/Sell'] = buy_or_sell\n",
    "\n",
    "        # The 'Buy/Sell' values need to be shifted up one row to match the 'Predicted_change' values\n",
    "        self.df_full['Buy/Sell'] = self.df_full['Buy/Sell'].shift(-1)\n",
    "        \n",
    "        self.df_full.drop(columns=['Pct_change_stock','compound','Compound_multiplied'],inplace = True)\n",
    "        \n",
    "    def sentimentScore(self, Tweet):\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        results = []\n",
    "        for sentence in Tweet:\n",
    "            vs = analyzer.polarity_scores(sentence)\n",
    "#             print(\"Vader score: \" + str(vs))\n",
    "            results.append(vs)\n",
    "        return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL',\n",
       " 'ADP',\n",
       " 'CERN',\n",
       " 'CSCO',\n",
       " 'EA',\n",
       " 'EBAY',\n",
       " 'EXPE',\n",
       " 'FISV',\n",
       " 'TXN',\n",
       " 'WDC',\n",
       " 'TMUS']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = []\n",
    "for root, dirs, files in os.walk('./Tweets'):\n",
    "    for _file in files:\n",
    "        if fnmatch.fnmatch(_file,'*.xlsx'):\n",
    "            txt.append(_file.split('.')[0])\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in txt:\n",
    "    temp = TweetPreprocessing(ticker)\n",
    "    temp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2020 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetPreprocessing:\n",
    "    PATH = \"Tweets/\"\n",
    "    def __init__(self,s):\n",
    "        self.stock = s\n",
    "        \n",
    "    def start(self):\n",
    "        self.getTweetData()\n",
    "        self.preprocessingTweet()\n",
    "        self.getYahooData()\n",
    "        self.preprocessingYahoo()\n",
    "        self.processingBoth()\n",
    "        self.df_full.to_csv('${}_backtest.csv'.format(self.stock))\n",
    "    \n",
    "    def getTweetData(self):\n",
    "        df = pd.read_csv('2020AAL.csv',encoding='latin-1')\n",
    "    \n",
    "        Tweet = df['Tweet content']\n",
    "        df_results = pd.DataFrame(self.sentimentScore(Tweet))\n",
    "        \n",
    "        # Combining the two dataframes\n",
    "        df_tweets = pd.merge(df, df_results, left_index=True, right_index=True)\n",
    "        \n",
    "        # Choose the common range for the dataframes to be used for all tweet data\n",
    "#         df_tweets = df_tweets[(df_tweets['Date'] >= '2016-03-28') & (df_tweets['Date'] <= '2016-06-15')]\n",
    "        \n",
    "        # Adding a datetime column\n",
    "        df_tweets['datetime'] = pd.to_datetime(df_tweets['Date']) # change of Date column to datetime columns        \n",
    "        # Slimming down the stream into a dataframe with only relevant columns\n",
    "      \n",
    "        self.df_tweet = df_tweets[['Favs','RTs','Followers','Following', 'Is a RT','compound','neg','neu','pos','datetime']]\n",
    "        \n",
    "    def preprocessingTweet(self):\n",
    "        # Remove tweets were compound is zero, i.e. sentiment is neutral\n",
    "        self.df_tweet = self.df_tweet[(self.df_tweet[['compound']] != 0).all(axis=1)]\n",
    "        \n",
    "        # Create new column with the 'compound' multiplied by nr of followers of the account\n",
    "        self.df_tweet['Compound_multiplied'] = self.df_tweet['compound'] * self.df_tweet['Followers']\n",
    "        \n",
    "        # Remove rows where 'Followers' is NaN\n",
    "        self.df_tweet.dropna(subset=['Followers'],inplace=True)\n",
    "        \n",
    "        # Scale the column \"Compound_multiplied\"\n",
    "        x_1 = self.df_tweet[['Compound_multiplied']].values.astype(float)\n",
    "\n",
    "        scaler = StandardScaler().fit(x_1)\n",
    "\n",
    "        scaled_data = scaler.transform(x_1)\n",
    "\n",
    "        self.df_tweet['Compound_multiplied_scaled'] = scaled_data\n",
    "        \n",
    "        # Create a dataframe with daily MEANS of each column\n",
    "        self.df_daily_mean=(self.df_tweet.groupby(self.df_tweet.datetime).mean())\n",
    "        \n",
    "        # Remove weekends from df_daily_mean\n",
    "        self.df_daily_mean = self.df_daily_mean[self.df_daily_mean.index.dayofweek < 5]\n",
    "        \n",
    "    def getYahooData(self):\n",
    "        #import pandas_datareader.data as web\n",
    "        start = dt.datetime(2020, 9, 28)\n",
    "        end =  dt.datetime(2020, 10, 16) #dt.datetime.now()\n",
    "\n",
    "        self.df_stock = web.DataReader(self.stock, 'yahoo', start, end)\n",
    "                \n",
    "    def preprocessingYahoo(self):\n",
    "        # measure of volatility\n",
    "        self.df_stock['HiLo_vola_stock'] = (self.df_stock['High'] - self.df_stock['Low']) / self.df_stock['Adj Close'] * 100.0\n",
    "        \n",
    "        # daily percent change\n",
    "        self.df_stock['Pct_change_stock'] = (self.df_stock['Close'] - self.df_stock['Open']) / self.df_stock['Open'] * 100.0\n",
    "        \n",
    "        \n",
    "    def processingBoth(self):\n",
    "        self.df_full = pd.concat([self.df_stock[['Volume','Adj Close','HiLo_vola_stock','Pct_change_stock']],\n",
    "                             self.df_daily_mean], axis=1, sort=False)\n",
    "        \n",
    "        # Impute missing data with their means\n",
    "        self.df_full[['Favs','RTs','Followers','Following','Is a RT','compound','neg','neu','pos','Compound_multiplied','Compound_multiplied_scaled']] \\\n",
    "        .fillna(value=self.df_full[['Favs','RTs','Followers','Following','Is a RT','compound','neg','neu','pos','Compound_multiplied','Compound_multiplied_scaled']].mean(),inplace=True)\n",
    "\n",
    "        # Remove missing Pct_change_stock data\n",
    "        self.df_full.dropna(subset=['Pct_change_stock'],inplace=True) \n",
    "        self.df_full.dropna(subset=['Compound_multiplied_scaled'],inplace=True) \n",
    "                \n",
    "        buy_or_sell = []\n",
    "        for i in self.df_full['Pct_change_stock']:\n",
    "            if i >= 0:\n",
    "                buy_or_sell.append(1)\n",
    "            elif i < 0:\n",
    "                buy_or_sell.append(-1)\n",
    "            else:\n",
    "                buy_or_sell.append(np.nan)\n",
    "\n",
    "        #Adds -1 or +1 to the column based on if 'Predicted_change' is negative or positive\n",
    "        self.df_full['Buy/Sell'] = buy_or_sell\n",
    "\n",
    "        # The 'Buy/Sell' values need to be shifted up one row to match the 'Predicted_change' values\n",
    "        self.df_full['Buy/Sell'] = self.df_full['Buy/Sell'].shift(-1)\n",
    "        \n",
    "        self.df_full.drop(columns=['Pct_change_stock','compound','Compound_multiplied'],inplace = True)\n",
    "        \n",
    "    def sentimentScore(self, Tweet):\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        results = []\n",
    "        for sentence in Tweet:\n",
    "            vs = analyzer.polarity_scores(sentence)\n",
    "#             print(\"Vader score: \" + str(vs))\n",
    "            results.append(vs)\n",
    "        return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc33\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "ticker = 'AAL'\n",
    "temp = TweetPreprocessing(ticker)\n",
    "temp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
